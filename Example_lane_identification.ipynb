{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs8goQy5Drw9TA9K/dMl95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/etivities/blob/main/Example_lane_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipeeEm24vSTS"
      },
      "source": [
        "#Lane Identification with Canny Algorithm & Hough Transform\n",
        "\n",
        "The Canny Algorithm & Hough Transform can be combined to make a simple traffic lane identification system.\n",
        "\n",
        "Steps:\n",
        "1. The edges in the image can be detected using the canny algorithm\n",
        "2. Masking is applied to the image in order to recover only edges corresponding to road markings.\n",
        "3. The hough transform is used to find lines that comprise the image.\n",
        "4. The found lines are extrapolated and averaged into lane boundaries.\n",
        "\n",
        "\n",
        "This notebook is based on the post https://www.kdnuggets.com/2017/07/road-lane-line-detection-using-computer-vision-models.html/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT3yPi2ra2GD"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMEBGUDH_0a7"
      },
      "source": [
        "# function to read images from Web addresses.\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\ttemp_image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\ttemp_image = cv2.imdecode(temp_image, cv2.IMREAD_COLOR)\n",
        "\ttemp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB) # OpenCV defaults to BGR, but we need RGB here..\n",
        "\treturn temp_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EFkINrglqVQ"
      },
      "source": [
        "#Load Image\n",
        "Image is imported from URL location and gaussian blur applied, the image is conveted to grey scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es4eOS9P_UKG"
      },
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/e/e7/New_A500_Dual_Carriageway_-_geograph.org.uk_-_65214.jpg\"\n",
        "image = url_to_image(image_url)\n",
        "plt.imshow(image)\n",
        "# Blur input image\n",
        "cv2.GaussianBlur(image, (5, 5), 0)\n",
        "# Convert to greyscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3JkYEuZw9XI"
      },
      "source": [
        "# Apply Canny Algorithm\n",
        "The open CV implementation of the canny algorithm is applied to find edges in the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u28Si1IO_3Ig"
      },
      "source": [
        "#Apply Canny Algorithm\n",
        "min_thres = 80\n",
        "max_thres = 150\n",
        "edges = cv2.Canny(gray,min_thres,max_thres,apertureSize = 3)\n",
        "plt.imshow(edges,'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhksVjNhxZn_"
      },
      "source": [
        "# Create Mask for Region of Interest.\n",
        "\n",
        "A Mask for the Region of Interest containing edges corresponding to lane markings recovered from the image can be created using the cv2.fillPoly command that can create a a filled region, the number of sides of the region is determined by the number of vertices applied. These are manually determined in this simple example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ltWTtm_5hQ"
      },
      "source": [
        "# points arranged clockwise\n",
        "l1 = [50,480]\n",
        "l2 = [250,350]\n",
        "r1 = [450,300]\n",
        "r2 = [600,320]\n",
        "r3 = [600,480]\n",
        "\n",
        "pts = np.array([[l1,l2,r1,r2,r3 ]], dtype=np.int32)\n",
        "\n",
        "#Mask region of Interest.\n",
        "def mask_img(image,vertices):\n",
        "    #Create mask\n",
        "    mask = np.zeros_like(edges)\n",
        "    #Add white to region of interest\n",
        "    cv2.fillPoly(mask, vertices, 255)\n",
        "    # apply mask to image\n",
        "    masked_image = cv2.bitwise_and(image,image, mask=mask)\n",
        "    return mask,masked_image\n",
        "\n",
        "mask,masked_image = mask_img(edges,pts)\n",
        "\n",
        "f, axarr = plt.subplots(1,2,figsize=(10,6))\n",
        "axarr[0].imshow(mask,'gray')\n",
        "axarr[0].title.set_text('Mask for Region of Interest')\n",
        "axarr[1].imshow((masked_image),'gray')\n",
        "axarr[1].title.set_text('Masked Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbXK7YQ-yNOn"
      },
      "source": [
        "#Hough Transform\n",
        "\n",
        "The Hough Transform is used to recover lines corresponding to the edges in the image. The [probablistic hough transform](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html) is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHxA09BMAWQA"
      },
      "source": [
        "# Reload image\n",
        "image = url_to_image(image_url)\n",
        "# Apply Hough Transform to find lines\n",
        "n_max = 40\n",
        "#hough lines\n",
        "rho_res = 1\n",
        "theta_res = np.pi/180\n",
        "threshold = 30\n",
        "min_line_len = 20\n",
        "max_line_gap = 20\n",
        "\n",
        "lines = cv2.HoughLinesP(masked_image,rho_res,theta_res,threshold, np.array([]),\n",
        "              minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
        "\n",
        "print(np.shape(lines))\n",
        "\n",
        "\n",
        "#lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
        "for line in lines:\n",
        "   x1,y1,x2,y2 = line[0]\n",
        "   cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "#for x1,y1,x2,y2 in lines[0:n_max]:\n",
        "#    cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ9Do3gVylGq"
      },
      "source": [
        "The lines produced by the Hough Transform correspond to the edges in the image. In order to determine the boundary of the lane, the lines are extrapolated and averaged using the function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYavCNK-eTCh"
      },
      "source": [
        "image = url_to_image(image_url)\n",
        "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
        "    \"\"\"\n",
        "    This function draws `lines` with `color` and `thickness`.\n",
        "    \"\"\"\n",
        "    imshape = img.shape\n",
        "\n",
        "    # these variables represent the y-axis coordinates to which\n",
        "    # the line will be extrapolated to\n",
        "    ymin_global = img.shape[0]\n",
        "    ymax_global = img.shape[0]\n",
        "\n",
        "    # left lane line variables\n",
        "    all_left_grad = []\n",
        "    all_left_y = []\n",
        "    all_left_x = []\n",
        "\n",
        "    # right lane line variables\n",
        "    all_right_grad = []\n",
        "    all_right_y = []\n",
        "    all_right_x = []\n",
        "\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            gradient, intercept = np.polyfit((x1,x2), (y1,y2), 1)\n",
        "            ymin_global = min(min(y1, y2), ymin_global)\n",
        "\n",
        "            if (gradient > 0):\n",
        "                all_left_grad += [gradient]\n",
        "                all_left_y += [y1, y2]\n",
        "                all_left_x += [x1, x2]\n",
        "            else:\n",
        "                all_right_grad += [gradient]\n",
        "                all_right_y += [y1, y2]\n",
        "                all_right_x += [x1, x2]\n",
        "\n",
        "    left_mean_grad = np.mean(all_left_grad)\n",
        "    left_y_mean = np.mean(all_left_y)\n",
        "    left_x_mean = np.mean(all_left_x)\n",
        "    left_intercept = left_y_mean - (left_mean_grad * left_x_mean)\n",
        "\n",
        "    right_mean_grad = np.mean(all_right_grad)\n",
        "    right_y_mean = np.mean(all_right_y)\n",
        "    right_x_mean = np.mean(all_right_x)\n",
        "    right_intercept = right_y_mean - (right_mean_grad * right_x_mean)\n",
        "\n",
        "    # Make sure we have some points in each lane line category\n",
        "    if ((len(all_left_grad) > 0) and (len(all_right_grad) > 0)):\n",
        "        upper_left_x = int((ymin_global - left_intercept) / left_mean_grad)\n",
        "        lower_left_x = int((ymax_global - left_intercept) / left_mean_grad)\n",
        "        upper_right_x = int((ymin_global - right_intercept) / right_mean_grad)\n",
        "        lower_right_x = int((ymax_global - right_intercept) / right_mean_grad)\n",
        "\n",
        "        cv2.line(img, (upper_left_x, ymin_global),\n",
        "                      (lower_left_x, ymax_global), color, thickness)\n",
        "        cv2.line(img, (upper_right_x, ymin_global),\n",
        "                      (lower_right_x, ymax_global), color, thickness)\n",
        "        # Add lane between the lines\n",
        "        lane = np.zeros_like(img)\n",
        "        vertices = np.array([[[lower_left_x, ymax_global],[upper_left_x, ymin_global],[upper_right_x, ymin_global],[lower_right_x, ymax_global]]], dtype=np.int32)\n",
        "        cv2.fillPoly(lane, vertices, (255,255,153))\n",
        "        final_img = cv2.addWeighted(img, 0.8, lane, 0.3, 0)\n",
        "\n",
        "    return final_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVmxj6taqVYB"
      },
      "source": [
        "final_img = draw_lines(image,lines)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(final_img)\n",
        "plt.title('Lane Boundary and Lane Region found from Hough Tranform Lines')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}