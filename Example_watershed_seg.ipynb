{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1eva16k1Xvs3e2ONAa+AU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/etivities/blob/main/Example_watershed_seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRMk_uEYeb8g"
      },
      "source": [
        "\n",
        "#Watershed Segmentation.\n",
        "\n",
        "In this example we will apply the openCV watershed algorithm to segment multiple touching objects from the background. The watershed algorithm is an example of a region growing segmentation algorithm. In order to use the watershed algorithm we must initially to prepare a marker image which outlines where the \"flooding\" sources/regions are for the watershed algorithm.  (Note that this example uses morphology operations. If you are not familar with these operations, they are discussed in the supplementary lesson 2: Morphology Operations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a43Joc5EXYU_"
      },
      "source": [
        "**Housekeeping:** Import Libraries, read image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frnFl6f8eVb7"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\ttemp_image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\ttemp_image = cv2.imdecode(temp_image, cv2.IMREAD_COLOR)\n",
        "\ttemp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB) # OpenCV defaults to BGR, but we need RGB here..\n",
        "\treturn temp_image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8k3z0w9nZfW"
      },
      "source": [
        "\n",
        "image_url = \"https://www.pyimagesearch.com/wp-content/uploads/2015/10/watershed_coins_01.jpg\"\n",
        "image = url_to_image(image_url)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTwMtyIoEz9"
      },
      "source": [
        "# Prepare marker Image\n",
        "\n",
        "**Step 1**: We must intially convert the image to greyscale and they apply thresholding. As we are required to use the threshold technique, we are limited to using the watershed algorithm on images where we can easily firstly segment all the combined foreground objects from background (This includes images with uniform backgrounds such as the image shown)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8gYAv5gL2N"
      },
      "source": [
        "# Convert to greyscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#Threshold the image\n",
        "\n",
        "# Use this form of Threshold command if objects are dark on light background\n",
        "#ret, thresh = cv2.threshold(gray,220,255,cv2.THRESH_BINARY_INV)\n",
        "# Use this form of Threshold command if objects are light on a dark background.\n",
        "ret, thresh = cv2.threshold(gray,80,255,cv2.THRESH_BINARY)\n",
        "\n",
        "# Create plots\n",
        "f, axarr = plt.subplots(1,2,figsize=(30,20))\n",
        "axarr[0].imshow(gray,'gray')\n",
        "axarr[0].title.set_text('Greyscale Image')\n",
        "axarr[1].imshow(thresh,'gray')\n",
        "axarr[1].title.set_text('Thresholded Image')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TKdiRkDpmH0"
      },
      "source": [
        "**Step 2**: We will then apply a closing operation to remove any holes in the image, this is follwed by an opening operating to remove the background noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NTUajn0impi"
      },
      "source": [
        "#Close this image\n",
        "str1 = 3\n",
        "str2 = 3\n",
        "\n",
        "#  Define closing structuring element\n",
        "closingKernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (str1,str1))\n",
        "\n",
        "# Create closed version removing noise in the foreground objects.\n",
        "closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, closingKernel,iterations = 2)\n",
        "\n",
        "# noise removal\n",
        "kernel = np.ones((str2,str2),np.uint8)\n",
        "opening = cv2.morphologyEx(closed,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "\n",
        "# Create plots\n",
        "f, axarr = plt.subplots(1,2,figsize=(30,20))\n",
        "axarr[0].imshow(closed,'gray')\n",
        "axarr[0].title.set_text('Closed Image')\n",
        "axarr[1].imshow(opening,'gray')\n",
        "axarr[1].title.set_text('Background Noise removed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdMj_KceqCYz"
      },
      "source": [
        "**Step 3**: Here we will find the object centres by applying the distance transform. We then apply another threshold operation to produce a binary image that includes the object centres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVNbUivi0jie"
      },
      "source": [
        "# Finding sure foreground area\n",
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
        "ret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)\n",
        "\n",
        "f, axarr = plt.subplots(1,2,figsize=(30,20))\n",
        "axarr[0].imshow(dist_transform,'gray')\n",
        "axarr[0].title.set_text('Distance Tranform')\n",
        "axarr[1].imshow(sure_fg,'gray')\n",
        "axarr[1].title.set_text('Applying Threshold to Distance Transform')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8uATxfr1a8M"
      },
      "source": [
        "**Step 4**: We want to obtain the unknown region to fill, this is where the water from the marked regions and background can flow and meet at edges. To obtain the unknown region this we subtract the object centres from a dilated version of the image obtained at the end of step 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZxNbyvqDKf"
      },
      "source": [
        "# sure background area\n",
        "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "\n",
        "# Finding unknown region\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "\n",
        "f, axarr = plt.subplots(1,2,figsize=(30,20))\n",
        "axarr[0].imshow(sure_bg,'gray')\n",
        "axarr[0].title.set_text('Sure Background')\n",
        "axarr[1].imshow((unknown),'gray')\n",
        "axarr[1].title.set_text('Unknown Region')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgjRl2vr2bDe"
      },
      "source": [
        "**Step 5**: Obtain the marker image that can be supplied to the watershed algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkbTb-WDfftu"
      },
      "source": [
        "# Marker labelling\n",
        "ret, markers = cv2.connectedComponents(sure_fg)\n",
        "\n",
        "# Add one to all labels so that sure background is not 0, but 1\n",
        "markers = markers+1\n",
        "\n",
        "# Now, mark the region of unknown with zero\n",
        "markers[unknown==255] = 0\n",
        "\n",
        "# plot figure\n",
        "plt.figure(figsize=(30,10))\n",
        "plt.title('Marker Image')\n",
        "plt.imshow(markers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF5RqWSA9xrP"
      },
      "source": [
        "**Step 6**: Apply the watershed Algorithm and display results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O5FIDG2fhOK"
      },
      "source": [
        "img= image\n",
        "# Modify markers with watershed and display edges\n",
        "markers = cv2.watershed(img,markers)\n",
        "image[markers == -1] = [255,0,0]\n",
        "\n",
        "# plot images\n",
        "f, axarr = plt.subplots(1,2,figsize=(30,20))\n",
        "axarr[0].imshow(image)\n",
        "axarr[0].title.set_text('Image with Edges')\n",
        "axarr[1].imshow(markers)\n",
        "axarr[1].title.set_text('Filled Regions')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}