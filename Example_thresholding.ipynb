{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHvRTarz58sFj7UPFj4Lr/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/etivities/blob/main/Example_thresholding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyIAmH67Wjuc"
      },
      "source": [
        "#Thresholding\n",
        "In this exmaple we will perform simple image segmentation of an image using thresholding. We will load an image from the web and view it's histograms, verifying the that it is suitable for thresholding. We will then apply OTSU's thresholding and close any gaps in the binary image giving us a final \"Mask\" Image.\n",
        "\n",
        "Things to try yourself in this Example:\n",
        "\n",
        "1: Find a new image from the web(replace the image_url link in the cell below). Verify that image is an unsuitable for thresholding by looking at the greyscale histogram. Hint: complex images with lots of colour will generally be unsuitable.\n",
        "\n",
        "2: Try and find an image from the web that could be segmented by thresholding. Hint: Any image that is close to being black and white or a dark forground object against a light background could be segmented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnKM2Qih-OzZ"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Function that allows test image to be read from the web\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\ttemp_image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\ttemp_image = cv2.imdecode(temp_image, cv2.IMREAD_COLOR)\n",
        "\ttemp_image = cv2.cvtColor(temp_image, cv2.COLOR_BGR2RGB) # OpenCV defaults to BGR, but we need RGB here..\n",
        "\treturn temp_image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1aq5zKk_XjU"
      },
      "source": [
        "Change URL link here to read in different images from the web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iyWLAUK_X4T"
      },
      "source": [
        "# read in test image\n",
        "image_url = \"https://st.depositphotos.com/1003591/3983/i/950/depositphotos_39832853-stock-photo-spices-heap-of-salt-on.jpg\"\n",
        "image = url_to_image(image_url)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C06LqneAY78k"
      },
      "source": [
        "#Gaussian Blur & Greyscale\n",
        "Next we will blur the image slightly. We can set the sigma parameter number and the size of the kernel.\n",
        "\n",
        "The blurred image must be converted to greyscale in order to find and apply the Thresholding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDnn7T5dBrss"
      },
      "source": [
        "# Add guassian blur\n",
        "\n",
        "sigma = 5   # Order of Gaussian\n",
        "# kernel size Must be approximately 6 x sigma and an odd number\n",
        "k_size = int(6*sigma+1)\n",
        "blur = cv2.GaussianBlur(image,(k_size,k_size),sigma)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoXHBQWJ_uJh"
      },
      "source": [
        "# Convert to greyscale\n",
        "gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDtYXDn1Bkw_"
      },
      "source": [
        "# Create plots\n",
        "f, axarr = plt.subplots(1,2,figsize=(10,20))\n",
        "axarr[0].imshow(blur,'gray')\n",
        "axarr[0].title.set_text('Blurred Image')\n",
        "axarr[1].imshow(gray,'gray')\n",
        "axarr[1].title.set_text('Greyscale Image')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VWVW7PiZypt"
      },
      "source": [
        "# Histograms\n",
        "\n",
        "Before we apply thresholding we want to verify that the image is suitable for thresholding to be applied. Therefore we will inspect the greyscale histogram. The histogram for the RGB colour channels is also generated just to observe it's distribution also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TItbnz9P-cYR"
      },
      "source": [
        "#plot Greyscale histogram\n",
        "plt.hist(gray.ravel(),256,[0,256]);\n",
        "\n",
        "\n",
        "plt.title('Greyscale Histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyvFa3FaBgXY"
      },
      "source": [
        "# Plot colour channel historgram\n",
        "color = ('b','g','r')\n",
        "for i,col in enumerate(color):\n",
        "    histr = cv2.calcHist([blur],[i],None,[256],[0,256])\n",
        "    plt.plot(histr,color = col)\n",
        "    plt.xlim([0,256])\n",
        "plt.title('Colour Histograms')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KERZZlEnmMg1"
      },
      "source": [
        "#Apply OTSU Threshold.\n",
        "Instead of manually selecting the thresold, the OTSU method automatically selects the best threshold that minimises the spread of pixels between foreground and background.\n",
        "\n",
        "We will also tidy up the produced mask, by adding a closing operation and then applying eroding to remove noise.\n",
        "\n",
        "In the first cell below we can adjust the size of the structuring elements for the closing and erosion operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-T4OHpEAtr4"
      },
      "source": [
        "# Closing operation structuring element\n",
        "str1 = 40\n",
        "# Erosion operation stucturing element\n",
        "str2 = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XbNgjNFLE-"
      },
      "source": [
        "# Apply OTSU Threshold\n",
        "ret2,otsu = cv2.threshold(gray,0,255, cv2.THRESH_OTSU)\n",
        "# Use this version if image has dark foreground object on light background\n",
        "#ret2,otsu = cv2.threshold(gray,0,255, cv2.THRESH_OTSU + cv2.THRESH_BINARY_INV)\n",
        "\n",
        "plt.imshow(otsu, cmap='gray')\n",
        "plt.title('Thresholding')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTtuY6KicnFG"
      },
      "source": [
        "# Apply a closing operation\n",
        "closingKernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (str1,str1))\n",
        "close = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, closingKernel)\n",
        "plt.imshow(close, cmap='gray')\n",
        "plt.title('Closing Applied')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9AmPLyJF6ku"
      },
      "source": [
        "# Apply\n",
        "eroded=cv2.erode(close,cv2.getStructuringElement(cv2.MORPH_RECT,(str2,str2)))\n",
        "plt.imshow(eroded, cmap='gray')\n",
        "plt.title('Erosion Applied')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwhYaH2Vbvee"
      },
      "source": [
        "# Apply Generated Mask to final Image\n",
        "\n",
        "We now overlay the mask in the orginal image to see how well we segmented the foreground image from the backgorund."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYqsBx4t3DyN"
      },
      "source": [
        "# Apply generated mask to final image\n",
        "mask_image = img1_bg = cv2.bitwise_and(image,image,mask = eroded)\n",
        "plt.imshow(mask_image)\n",
        "plt.title('Final Masked Image')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}